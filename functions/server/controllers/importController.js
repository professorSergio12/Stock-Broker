'use strict';

const XLSX = require('xlsx');
const catalyst = require('zcatalyst-sdk-node');
const DEFAULT_TABLE = 'Transaction';

// In-memory progress tracker (per runtime instance)
const IMPORT_PROGRESS = new Map();

function newImportId() {
	return Date.now().toString(36) + Math.random().toString(36).slice(2, 8);
}

// Allowed columns as per Data Store schema (underscore-separated)
const ALLOWED_COLUMNS = new Set([
	'WS_client_id','WS_Account_code','TRANDATE','SETDATE','Tran_Type','Tran_Desc',
	'Security_Type','Security_Type_Description','DETAILTYPENAME','ISIN','Security_code',
	'Security_Name','EXCHG','BROKERCODE','Depository_Registrar','DPID_AMC','Dp_Client_id_Folio',
	'BANKCODE','BANKACID','QTY','RATE','BROKERAGE','SERVICETAX','NETRATE','Net_Amount','STT',
	'TRFDATE','TRFRATE','TRFAMT','TOTAL_TRXNFEE','TOTAL_TRXNFEE_STAX','Txn_Ref_No','DESCMEMO',
	'CHEQUENO','CHEQUEDTL','PORTFOLIOID','DELIVERYDATE','PAYMENTDATE','ACCRUEDINTEREST','ISSUER',
	'ISSUERNAME','TDSAMOUNT','STAMPDUTY','TPMSGAIN','RMID','RMNAME','ADVISORID','ADVISORNAME',
	'BRANCHID','BRANCHNAME','GROUPID','GROUPNAME','OWNERID','OWNERNAME','WEALTHADVISOR_NAME',
	'SCHEMEID','SCHEMENAME'
]);

// Columns that must be numeric
const NUMERIC_COLUMNS = new Set([
	'QTY','RATE','BROKERAGE','SERVICETAX','NETRATE','Net_Amount','STT','TRFRATE','TRFAMT',
	'TOTAL_TRXNFEE','TOTAL_TRXNFEE_STAX','TDSAMOUNT','STAMPDUTY','TPMSGAIN','ACCRUEDINTEREST'
]);

// Map Excel column names (with spaces/special chars) to database field names (with underscores)
const COLUMN_MAPPING = {
	'WS client id': 'WS_client_id',
	'WS Client id': 'WS_client_id',
	'WS_client_id': 'WS_client_id',
	'WS Account code': 'WS_Account_code',
	'WS_Account_code': 'WS_Account_code',
	'TRANDATE': 'TRANDATE',
	'TRANDATE': 'TRANDATE',
	'SETDATE': 'SETDATE',
	'Set Date': 'SETDATE',
	'Tran Type': 'Tran_Type',
	'Tran_Type': 'Tran_Type',
	'Tran Desc': 'Tran_Desc',
	'Tran_Desc': 'Tran_Desc',
	'Security Type': 'Security_Type',
	'Security_Type': 'Security_Type',
	'Security Type Description': 'Security_Type_Description',
	'Security_Type_Description': 'Security_Type_Description',
	'DETAILTYPENAME': 'DETAILTYPENAME',
	'Detail Type Name': 'DETAILTYPENAME',
	'ISIN': 'ISIN',
	'Security code': 'Security_code',
	'Security_code': 'Security_code',
	'Security Name': 'Security_Name',
	'Security_Name': 'Security_Name',
	'EXCHG': 'EXCHG',
	'Exchange': 'EXCHG',
	'BROKERCODE': 'BROKERCODE',
	'Broker Code': 'BROKERCODE',
	'Depository/Registrar': 'Depository_Registrar',
	'Depositoy/Registrar': 'Depository_Registrar',
	'DPID/AMC': 'DPID_AMC',
	'Dp Client id/Folio': 'Dp_Client_id_Folio',
	'DP Client id/Folio': 'Dp_Client_id_Folio',
	'BANKCODE': 'BANKCODE',
	'Bank Code': 'BANKCODE',
	'BANKACID': 'BANKACID',
	'Bank AC ID': 'BANKACID',
	'QTY': 'QTY',
	'Quantity': 'QTY',
	'RATE': 'RATE',
	'Rate': 'RATE',
	'BROKERAGE': 'BROKERAGE',
	'Brokerage': 'BROKERAGE',
	'SERVICETAX': 'SERVICETAX',
	'Service Tax': 'SERVICETAX',
	'NETRATE': 'NETRATE',
	'Net Rate': 'NETRATE',
	'Net Amount': 'Net_Amount',
	'NET_Amount': 'Net_Amount',
	'STT': 'STT',
	'TRFDATE': 'TRFDATE',
	'TRF Date': 'TRFDATE',
	'TRFRATE': 'TRFRATE',
	'TRF Rate': 'TRFRATE',
	'TRFAMT': 'TRFAMT',
	'TRF Amount': 'TRFAMT',
	'TOTAL_TRXNFEE': 'TOTAL_TRXNFEE',
	'Total Txn Fee': 'TOTAL_TRXNFEE',
	'TOTAL_TRXNFEE_STAX': 'TOTAL_TRXNFEE_STAX',
	'Total Txn Fee STax': 'TOTAL_TRXNFEE_STAX',
	'Txn Ref No': 'Txn_Ref_No',
	'TXN_Ref_No': 'Txn_Ref_No',
	'DESCMEMO': 'DESCMEMO',
	'Desc Memo': 'DESCMEMO',
	'CHEQUENO': 'CHEQUENO',
	'Cheque No': 'CHEQUENO',
	'CHEQUEDTL': 'CHEQUEDTL',
	'Cheque Dtl': 'CHEQUEDTL',
	'PORTFOLIOID': 'PORTFOLIOID',
	'Portfolio ID': 'PORTFOLIOID',
	'DELIVERYDATE': 'DELIVERYDATE',
	'Delivery Date': 'DELIVERYDATE',
	'PAYMENTDATE': 'PAYMENTDATE',
	'Payment Date': 'PAYMENTDATE',
	'ACCRUEDINTEREST': 'ACCRUEDINTEREST',
	'Accrued Interest': 'ACCRUEDINTEREST',
	'ISSUER': 'ISSUER',
	'Issuer': 'ISSUER',
	'ISSUERNAME': 'ISSUERNAME',
	'Issuer Name': 'ISSUERNAME',
	'TDSAMOUNT': 'TDSAMOUNT',
	'TDS Amount': 'TDSAMOUNT',
	'STAMPDUTY': 'STAMPDUTY',
	'Stamp Duty': 'STAMPDUTY',
	'TPMSGAIN': 'TPMSGAIN',
	'TPMSGain': 'TPMSGAIN',
	'RMID': 'RMID',
	'RM ID': 'RMID',
	'RMNAME': 'RMNAME',
	'RM Name': 'RMNAME',
	'ADVISORID': 'ADVISORID',
	'Advisor ID': 'ADVISORID',
	'ADVISORNAME': 'ADVISORNAME',
	'Advisor Name': 'ADVISORNAME',
	'BRANCHID': 'BRANCHID',
	'Branch ID': 'BRANCHID',
	'BRANCHNAME': 'BRANCHNAME',
	'Branch Name': 'BRANCHNAME',
	'GROUPID': 'GROUPID',
	'Group ID': 'GROUPID',
	'GROUPNAME': 'GROUPNAME',
	'Group Name': 'GROUPNAME',
	'OWNERID': 'OWNERID',
	'Owner ID': 'OWNERID',
	'OWNERNAME': 'OWNERNAME',
	'Owner Name': 'OWNERNAME',
	'WEALTHADVISOR NAME': 'WEALTHADVISOR_NAME',
	'Wealth Advisor Name': 'WEALTHADVISOR_NAME',
	'SCHEMEID': 'SCHEMEID',
	'Scheme ID': 'SCHEMEID',
	'SCHEMENAME': 'SCHEMENAME',
	'Scheme Name': 'SCHEMENAME'
};

// Canonicalize helper to match headers regardless of spaces, dots, slashes or case
function canonicalize(name) {
	return String(name || '')
		.toLowerCase()
		.replace(/[^a-z0-9]/g, ''); // remove all non-alphanumerics
}

// Precompute canonical -> schema column map
const CANONICAL_TO_SCHEMA = (() => {
	const map = {};
	ALLOWED_COLUMNS.forEach(col => {
		map[canonicalize(col)] = col;
	});
	return map;
})();

function normalizeColumnName(excelColName) {
	if (!excelColName) return null;
	const trimmed = String(excelColName).trim();

	// 1) Direct explicit overrides
	if (COLUMN_MAPPING[trimmed]) return COLUMN_MAPPING[trimmed];

	// 2) Replace common separators with underscore and test direct match
	const underscored = trimmed.replace(/[.\s\/-]+/g, '_');
	if (ALLOWED_COLUMNS.has(underscored)) return underscored;

	// 3) Canonical fuzzy match to schema
	const canon = canonicalize(trimmed);
	if (CANONICAL_TO_SCHEMA[canon]) return CANONICAL_TO_SCHEMA[canon];

	// 4) Fallback to underscored (will be flagged unknown later if not allowed)
	return underscored;
}

function coerceValueForColumn(column, value) {
	if (value === null || value === '') return null;
	if (NUMERIC_COLUMNS.has(column)) {
		const num = Number(value);
		return isNaN(num) ? null : num;
	}
	return value;
}

function parseExcelFile(buffer) {
	try {
		const workbook = XLSX.read(buffer, { type: 'buffer' });
		const firstSheetName = workbook.SheetNames[0];
		const worksheet = workbook.Sheets[firstSheetName];
		const jsonData = XLSX.utils.sheet_to_json(worksheet, { raw: false, defval: null });
		return jsonData;
	} catch (err) {
		throw new Error(`Failed to parse Excel file: ${err.message}`);
	}
}

function mapRowToDatabaseFormat(excelRow) {
	const dbRow = {};
	// date columns as per schema
	const dateColumns = new Set([
		'TRANDATE','SETDATE','DELIVERYDATE','PAYMENTDATE','TRFDATE'
	]);

	// Track unknown columns for diagnostics
	const unknownColumns = [];

	Object.keys(excelRow).forEach(excelKey => {
		const dbKey = normalizeColumnName(excelKey);
		if (dbKey) {
			let value = excelRow[excelKey];
			// Convert empty strings to null
			if (value === '' || value === undefined) {
				value = null;
			}
			// Normalize dates to YYYY-MM-DD
			if (value && dateColumns.has(dbKey)) {
				// Handle Excel date or string dates
				const d = new Date(value);
				if (!isNaN(d.getTime())) {
					const yyyy = d.getFullYear();
					const mm = String(d.getMonth() + 1).padStart(2, '0');
					const dd = String(d.getDate()).padStart(2, '0');
					value = `${yyyy}-${mm}-${dd}`;
				}
			}
			// Keep numbers as numbers, others as strings/null
			if (ALLOWED_COLUMNS.has(dbKey)) {
				dbRow[dbKey] = coerceValueForColumn(dbKey, value);
			} else {
				unknownColumns.push(dbKey);
			}
		}
	});

	// Attach list of unknowns for later debugging (not inserted)
	if (unknownColumns.length) {
		dbRow.__unknown = unknownColumns;
	}
	return dbRow;
}

exports.importExcel = async (req, res) => {
	try {
		const app = req.catalystApp;
		if (!app) {
			return res.status(500).json({ 
				success: false, 
				error: 'Catalyst app context missing' 
			});
		}

		if (!req.file) {
			return res.status(400).json({ 
				success: false, 
				error: 'No file uploaded' 
			});
		}

		// Store file buffer before async context (req.file.buffer might not be available later)
		const fileBuffer = Buffer.from(req.file.buffer);
		const fileName = req.file.originalname;
		const fileSize = req.file.size;

		// Start async import and return importId immediately
		const importId = newImportId();
		IMPORT_PROGRESS.set(importId, {
			stage: 'parsing',
			progress: 5,
			message: 'Parsing Excel...',
			totalRows: 0,
			processedRows: 0,
			imported: 0,
			errors: 0,
			errorDetails: []
		});

		// Kick off background processing
		setImmediate(async () => {
			const tableName = DEFAULT_TABLE;
			const progress = IMPORT_PROGRESS.get(importId);
			try {
				console.log(`[Import ${importId}] Starting import: ${fileName} (${fileSize} bytes)`);

				// Re-initialize Catalyst app in async context
				const appAsync = catalyst.initialize(req);
				if (!appAsync) {
					throw new Error('Failed to initialize Catalyst app');
				}

				// Parse Excel using stored buffer
				console.log(`[Import ${importId}] Parsing Excel file...`);
				let excelRows;
				try {
					excelRows = parseExcelFile(fileBuffer);
				} catch (parseErr) {
					console.error(`[Import ${importId}] Parse error:`, parseErr);
					throw new Error(`Failed to parse Excel: ${parseErr.message}`);
				}
				if (!excelRows || excelRows.length === 0) {
					throw new Error('Excel file is empty or has no data rows');
				}

				console.log(`[Import ${importId}] Parsed ${excelRows.length} rows from Excel`);
				progress.totalRows = excelRows.length;
				progress.stage = 'mapping';
				progress.progress = 15;
				progress.message = 'Mapping columns...';

				// Map rows
				console.log(`[Import ${importId}] Mapping columns to database schema...`);
				const mappedRows = excelRows.map((row, idx) => {
					try {
						return mapRowToDatabaseFormat(row);
					} catch (mapErr) {
						console.error(`[Import ${importId}] Error mapping row ${idx + 1}:`, mapErr);
						return null;
					}
				}).filter(row => {
					if (!row) return false;
					const values = Object.entries(row)
						.filter(([k]) => k !== '__unknown')
						.map(([, v]) => v);
					return values.some(val => val !== null && val !== '');
				});

				console.log(`[Import ${importId}] Mapped ${mappedRows.length} valid rows`);
				if (mappedRows.length === 0) {
					throw new Error('No valid rows found after mapping. Check column headers match schema.');
				}

				// Unknown sample, remove helper
				const unknownSample = new Set();
				mappedRows.forEach((r, idx) => {
					if (idx < 5 && Array.isArray(r.__unknown)) {
						r.__unknown.forEach(c => unknownSample.add(c));
					}
					if ('__unknown' in r) delete r.__unknown;
				});

				if (unknownSample.size > 0) {
					console.warn(`[Import ${importId}] Unknown columns detected:`, Array.from(unknownSample));
				}

				// Insert
				progress.stage = 'inserting';
				progress.progress = 25;
				progress.message = 'Inserting into Data Store...';

				const datastore = appAsync.datastore();
				const table = datastore.table(tableName);
				let totalInserted = 0;
				let errorCount = 0;
				const errorMessages = [];
				const BATCH_SIZE = 500;

				console.log(`[Import ${importId}] Starting batch insert (batch size: ${BATCH_SIZE})...`);

				const insertBatch = async (batch) => {
					if (typeof table.insertRows === 'function') {
						await table.insertRows(batch);
					} else if (typeof table.bulkWriteRows === 'function') {
						await table.bulkWriteRows(batch);
					} else if (typeof table.insertRow === 'function') {
						for (const row of batch) {
							await table.insertRow(row);
						}
					} else {
						throw new Error('No suitable insert method available');
					}
				};

				for (let i = 0; i < mappedRows.length; i += BATCH_SIZE) {
					const batch = mappedRows.slice(i, i + BATCH_SIZE);
					const batchNum = Math.floor(i / BATCH_SIZE) + 1;
					try {
						console.log(`[Import ${importId}] Inserting batch ${batchNum} (rows ${i + 1}-${Math.min(i + BATCH_SIZE, mappedRows.length)})...`);
						await insertBatch(batch);
						totalInserted += batch.length;
						console.log(`[Import ${importId}] Batch ${batchNum} inserted successfully`);
					} catch (batchErr) {
						console.error(`[Import ${importId}] Batch ${batchNum} failed:`, batchErr.message);
						// Try per-row fallback
						for (let j = 0; j < batch.length; j++) {
							const row = batch[j];
							try {
								if (typeof table.insertRow === 'function') {
									await table.insertRow(row);
									totalInserted++;
								} else if (typeof table.bulkWriteRows === 'function') {
									await table.bulkWriteRows([row]);
									totalInserted++;
								} else {
									throw new Error('No per-row insert available');
								}
							} catch (rowErr) {
								errorCount++;
								const errMsg = `Row ${i + j + 1}: ${rowErr.message}`;
								errorMessages.push(errMsg);
								if (errorMessages.length <= 10) {
									console.error(`[Import ${importId}] ${errMsg}`);
								}
							}
						}
					}
					progress.processedRows = Math.min(i + batch.length, mappedRows.length);
					progress.imported = totalInserted;
					progress.errors = errorCount;
					progress.errorDetails = errorMessages.slice(0, 10);
					progress.progress = Math.min(95, Math.round((progress.processedRows / mappedRows.length) * 90) + 5);
					progress.message = `Inserted ${totalInserted}/${mappedRows.length} rows...`;
					IMPORT_PROGRESS.set(importId, progress);
				}

				console.log(`[Import ${importId}] Import completed: ${totalInserted} inserted, ${errorCount} errors`);
				progress.stage = 'completed';
				progress.progress = 100;
				progress.message = `Imported ${totalInserted} of ${mappedRows.length} rows${errorCount > 0 ? ` (${errorCount} errors)` : ''}`;
				progress.unknownColumns = Array.from(unknownSample);
			} catch (err) {
				console.error(`[Import ${importId}] Fatal error:`, err);
				progress.stage = 'error';
				progress.message = err.message || 'Import failed';
				progress.errorDetails = [err.toString()];
				if (err.stack) {
					console.error(`[Import ${importId}] Stack:`, err.stack);
				}
			}
			IMPORT_PROGRESS.set(importId, progress);
		});

		return res.status(200).json({
			success: true,
			importId,
			message: 'Import started'
		});

	} catch (err) {
		console.error('Import error:', err);
		return res.status(500).json({ 
			success: false, 
			error: `Failed to import Excel file: ${err.message}` 
		});
	}
};

exports.getImportProgress = async (req, res) => {
	const { id } = req.params;
	const state = IMPORT_PROGRESS.get(id);
	if (!state) {
		return res.status(404).json({ success: false, error: 'Import not found' });
	}
	// Prevent caching so clients don't get 304 Not Modified
	res.set('Cache-Control', 'no-store, no-cache, must-revalidate, proxy-revalidate');
	res.set('Pragma', 'no-cache');
	res.set('Expires', '0');
	return res.status(200).json({ success: true, progress: state });
};

// Test endpoint to insert dummy data and verify database insertion works
exports.testInsert = async (req, res) => {
	try {
		const app = req.catalystApp;
		if (!app) {
			return res.status(500).json({ 
				success: false, 
				error: 'Catalyst app context missing' 
			});
		}

		const tableName = DEFAULT_TABLE;
		
		// Create a simple dummy row with required fields
		const dummyRow = {
			WS_client_id: 'TEST_' + Date.now(),
			WS_Account_code: 'TEST_ACCOUNT',
			TRANDATE: new Date().toISOString().split('T')[0], // YYYY-MM-DD format
			SETDATE: new Date().toISOString().split('T')[0],
			Tran_Type: 'Buy',
			Tran_Desc: 'Test Import',
			Security_Type: 'Equity',
			Security_Name: 'TEST_STOCK',
			Security_code: 'TEST',
			EXCHG: 'NSE',
			QTY: 10,
			RATE: 100.50,
			Net_Amount: 1005.00
		};

		// Get Data Store instance and table
		const datastore = app.datastore();
		const table = datastore.table(tableName);

		console.log('Attempting to insert dummy row:', dummyRow);

		// Try to insert the row
		let insertResult;
		try {
			// Try insertRow first (most common method)
			if (typeof table.insertRow === 'function') {
				insertResult = await table.insertRow(dummyRow);
				console.log('insertRow result:', insertResult);
			} else if (typeof table.insertRows === 'function') {
				insertResult = await table.insertRows([dummyRow]);
				console.log('insertRows result:', insertResult);
			} else if (typeof table.bulkWriteRows === 'function') {
				insertResult = await table.bulkWriteRows([dummyRow]);
				console.log('bulkWriteRows result:', insertResult);
			} else {
				return res.status(500).json({ 
					success: false, 
					error: 'No insert method found on table object. Available methods: ' + Object.keys(table).join(', ')
				});
			}
		} catch (insertErr) {
			console.error('Insert error details:', insertErr);
			return res.status(500).json({ 
				success: false, 
				error: `Insert failed: ${insertErr.message}`,
				details: insertErr.toString(),
				stack: insertErr.stack
			});
		}

		// Verify by querying the inserted row
		const zcql = app.zcql();
		const verifyQuery = `SELECT * FROM ${tableName} WHERE WS_client_id = ? ORDER BY CREATEDTIME DESC LIMIT 1`;
		const verifyResult = await zcql.executeZCQLQuery(verifyQuery, [dummyRow.WS_client_id]);

		return res.status(200).json({
			success: true,
			message: 'Dummy data inserted successfully',
			insertResult: insertResult,
			insertedRow: dummyRow,
			verified: verifyResult && verifyResult.length > 0 ? verifyResult[0] : null,
			verificationCount: verifyResult ? verifyResult.length : 0
		});

	} catch (err) {
		console.error('Test insert error:', err);
		return res.status(500).json({ 
			success: false, 
			error: `Test insert failed: ${err.message}`,
			details: err.toString(),
			stack: err.stack
		});
	}
};

